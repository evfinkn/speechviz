# Speech Visualization

This will take an audio file and visualize various characteristics. Currently, you can see when speakers speak in the file and when there is voice activity (and conversely no voice activity). Additionally, you can play any given segment of speech by a given speaker by pressing the play button. If you press the loop button right next to it, the segment will play on repeat.

## Installation

```
git clone https://research-git.uiowa.edu/uiowa-audiology-reu-2022/speechviz.git
cd speechviz
npm install
npm run mkdir
python db_init.py
```
To use process_audio and the pipeline, you'll need to first make a conda environment. If installing on Linux or Windows, you can create the environment using the environment.yml file (you will still need to install audiowaveform and ffmpeg manually (check `conda list` for ffmpeg, might've been installed automatically)):
```
conda env create -f environment.yml
```  
<br><br>
Otherwise, you can create the environment manually:
```
conda create -n speechviz
conda activate speechviz
conda install pytorch numpy torchvision torchaudio cudatoolkit=11.3 -c pytorch
```
Then, install [pyannotate.audio](https://github.com/pyannote/pyannote-audio) and speechbrain with pip:
```
pip install pyannote.audio
pip install speechbrain
```
<br>
You also need to install [audiowaveform](https://github.com/bbc/audiowaveform#installation) and [ffmpeg](https://ffmpeg.org/download.html) (check `conda list` for ffmpeg, might've been installed automatically).

## Usage
Before running the server, you'll need to process some audio. To do so, run:
```
python process_audio.py FILE
```
For more information, run:
```
python process_audio.py -h
```
<br><br>
To start the server, run:
```
npm start
```
and then open http://localhost:3000 in your browser.

By default, the server listens on port 3000. To specify a different port, run with the port option:
```
npm start -- --port=PORT
```
where PORT is the port you want the server to listen on.
<br>
<br>
To actually display any audio, you need to:
1. Add the audio file to the `data/audio` directory.
2. Add the json file for the waveform (generated by the pipeline) to the `data/waveforms` directory.
3. Add the json file for the segments (generated by the pipeline) to the `data/segments` directory.

For example, for the file `example.mp3`, there should be `data/audio/example.mp3`, `data/waveforms/example-waveform.json`, and `data/segments/example-segments.json`.

## Troubleshooting

If installing on Bigcore, you are likely to run into the following error:
```
ERROR: Could not install packages due to an OSError: Proxy URL had no scheme, should start with http:// or https://
```
To resolve this, run the following command:
```
http_proxy="http://$(echo $http_proxy)" && https_proxy="http://$(echo $https_proxy)"
```
<br>
<br>

If you receive this error:
```
subprocess.CalledProcessError: Command '['ffmpeg', '-y', '-i', 'input_file_here' 'output_file_here']' returned non-zero exit status 127.
```
Running
```
conda update ffmpeg
```
should resolve the issue.
